{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHYnNGF68f9R"
      },
      "source": [
        "**Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL9FrseNEzJf"
      },
      "outputs": [],
      "source": [
        "!pip install pypdfium2\n",
        "!pip install PyArabic\n",
        "!pip install langdetect\n",
        "!pip install arabic-reshaper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bCZwhUMXQMZH"
      },
      "outputs": [],
      "source": [
        "import pypdfium2 as pdfium\n",
        "import pandas\n",
        "from itertools import chain\n",
        "import re\n",
        "import arabic_reshaper\n",
        "from pyarabic.araby import tokenize, is_arabicrange, strip_tashkeel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93K7ddOVoThJ"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "e_yEfxvZGKSh"
      },
      "outputs": [],
      "source": [
        "def clean_data(text_part):\n",
        "    text_part = text_part.replace('\\r\\n', ' ')\n",
        "    text_part = text_part.lstrip()\n",
        "    text_part = text_part.lstrip('1')\n",
        "    text_part = text_part.lstrip('2')\n",
        "    text_part = text_part.lstrip('3')\n",
        "    text_part = text_part.lstrip('4')\n",
        "    text_part = text_part.lstrip('5')\n",
        "    text_part = text_part.lstrip('6')\n",
        "    text_part = text_part.lstrip('7')\n",
        "    text_part = text_part.lstrip('8')\n",
        "    text_part = text_part.lstrip('9')\n",
        "    text_part = text_part.lstrip('10')\n",
        "    text_part = text_part.lstrip('I')\n",
        "    text_part = text_part.lstrip('II')\n",
        "    text_part = text_part.lstrip('III')\n",
        "    text_part = text_part.lstrip('IV')\n",
        "    text_part = text_part.lstrip('V')\n",
        "    text_part = text_part.lstrip('VI')\n",
        "    text_part = text_part.lstrip('VII')\n",
        "    text_part = text_part.lstrip('VIII')\n",
        "    text_part = text_part.lstrip('IX')\n",
        "    text_part = text_part.lstrip('X')\n",
        "    text_part = text_part.lstrip('i')\n",
        "    text_part = text_part.lstrip('ii')\n",
        "    text_part = text_part.lstrip('iii')\n",
        "    text_part = text_part.lstrip('iv')\n",
        "    text_part = text_part.lstrip('v')\n",
        "    text_part = text_part.lstrip('vi')\n",
        "    text_part = text_part.lstrip('vii')\n",
        "    text_part = text_part.lstrip('viii')\n",
        "    text_part = text_part.lstrip('ix')\n",
        "    text_part = text_part.lstrip('x')\n",
        "\n",
        "    text_part = re.compile(re.escape(\"abstract\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"summary\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"outline\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"keywords\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"key words\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"key-words\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"index terms\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"index-terms\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"résumé\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"résume\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"resumé\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"resume\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots clés\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots clé\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots-clés\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots-clé\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots cles\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots cle\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots-cles\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"mots-cle\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"motscles\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"motsclés\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"termes d''indexation\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"termes-d''indexation\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"termes indexation\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"termes-indexation\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"ملخص\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"الملخص\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"الكلمات المفتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"الكلمات-المفتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"الكلمات الافتتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"الكلمات-الافتتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"الكلمات المفتاح\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"الكلمات-المفتاح\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"كلمات مفتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"كلمات-مفتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"كلمات افتتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"كلمات-افتتاحية\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"كلمات مفتاح\"), re.IGNORECASE).sub('', text_part)\n",
        "    text_part = re.compile(re.escape(\"كلمات-مفتاح\"), re.IGNORECASE).sub('', text_part)\n",
        "\n",
        "    text_part = text_part.lstrip()\n",
        "    text_part = re.sub(' +', ' ', text_part)\n",
        "    text_part = text_part.lstrip(':')\n",
        "    text_part = text_part.lstrip('-')\n",
        "    text_part = text_part.lstrip('_')\n",
        "    text_part = text_part.lstrip('.')\n",
        "    text_part = text_part.rstrip()\n",
        "    return text_part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "VM41nomcGNL_"
      },
      "outputs": [],
      "source": [
        "def abstract_english(height, width, textpage):\n",
        "\n",
        "    position = ()\n",
        "    \n",
        "    searcher_1 = textpage.search(\"abstract\", match_case=False, match_whole_word=True)\n",
        "    position_1 = searcher_1.get_next()\n",
        "    searcher_2 = textpage.search(\"summary\", match_case=False, match_whole_word=True)\n",
        "    position_2 = searcher_2.get_next()\n",
        "    searcher_3 = textpage.search(\"outline\", match_case=False, match_whole_word=True)\n",
        "    position_3 = searcher_3.get_next()\n",
        "\n",
        "    if position_1:\n",
        "        position = position_1\n",
        "    elif position_2:\n",
        "        position = position_2\n",
        "    elif position_3:\n",
        "        position = position_3\n",
        "    \n",
        "    if position:\n",
        "        return textpage.get_text_bounded(left=0, right=width, top=position[0][3])\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def keywords_english(height, width, textpage):\n",
        "\n",
        "    position = ()\n",
        "    \n",
        "    searcher_1 = textpage.search(\"keywords\", match_case=False, match_whole_word=True)\n",
        "    position_1 = searcher_1.get_next()\n",
        "    searcher_2 = textpage.search(\"key words\", match_case=False, match_whole_word=True)\n",
        "    position_2 = searcher_2.get_next()\n",
        "    searcher_3 = textpage.search(\"key-words\", match_case=False, match_whole_word=True)\n",
        "    position_3 = searcher_3.get_next()\n",
        "    searcher_4 = textpage.search(\"index terms\", match_case=False, match_whole_word=True)\n",
        "    position_4 = searcher_4.get_next()\n",
        "    searcher_5 = textpage.search(\"index-terms\", match_case=False, match_whole_word=True)\n",
        "    position_5 = searcher_5.get_next()\n",
        "\n",
        "    if position_1:\n",
        "        position = position_1\n",
        "    elif position_2:\n",
        "        position = position_2\n",
        "    elif position_3:\n",
        "        position = position_3\n",
        "    elif position_4:\n",
        "        position = position_4\n",
        "    elif position_5:\n",
        "        position = position_5\n",
        "    \n",
        "    if position:\n",
        "        return textpage.get_text_bounded(left=0, right=width, top=position[0][3])\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def abstract_french(height, width, textpage):\n",
        "\n",
        "    position = ()\n",
        "    \n",
        "    searcher_1 = textpage.search(\"résumé\", match_case=False, match_whole_word=True)\n",
        "    position_1 = searcher_1.get_next()\n",
        "    searcher_2 = textpage.search(\"résume\", match_case=False, match_whole_word=True)\n",
        "    position_2 = searcher_2.get_next()\n",
        "    searcher_3 = textpage.search(\"resumé\", match_case=False, match_whole_word=True)\n",
        "    position_3 = searcher_3.get_next()\n",
        "    searcher_4 = textpage.search(\"resume\", match_case=False, match_whole_word=True)\n",
        "    position_4 = searcher_4.get_next()\n",
        "\n",
        "    if position_1:\n",
        "        position = position_1\n",
        "    elif position_2:\n",
        "        position = position_2\n",
        "    elif position_3:\n",
        "        position = position_3\n",
        "    elif position_4:\n",
        "        position = position_4\n",
        "    \n",
        "    if position:\n",
        "        return textpage.get_text_bounded(left=0, right=width, top=position[0][3])\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def keywords_french(height, width, textpage):\n",
        "\n",
        "    position = ()\n",
        "    \n",
        "    searcher_1 = textpage.search(\"mots clés\", match_case=False, match_whole_word=True)\n",
        "    position_1 = searcher_1.get_next()\n",
        "    searcher_2 = textpage.search(\"mots clé\", match_case=False, match_whole_word=True)\n",
        "    position_2 = searcher_2.get_next()\n",
        "    searcher_3 = textpage.search(\"mots-clés\", match_case=False, match_whole_word=True)\n",
        "    position_3 = searcher_3.get_next()\n",
        "    searcher_4 = textpage.search(\"mots-clé\", match_case=False, match_whole_word=True)\n",
        "    position_4 = searcher_4.get_next()\n",
        "    searcher_5 = textpage.search(\"mots cles\", match_case=False, match_whole_word=True)\n",
        "    position_5 = searcher_5.get_next()\n",
        "    searcher_6 = textpage.search(\"mots cle\", match_case=False, match_whole_word=True)\n",
        "    position_6 = searcher_6.get_next()\n",
        "    searcher_7 = textpage.search(\"mots-cles\", match_case=False, match_whole_word=True)\n",
        "    position_7 = searcher_7.get_next()\n",
        "    searcher_8 = textpage.search(\"mots-cle\", match_case=False, match_whole_word=True)\n",
        "    position_8 = searcher_8.get_next()\n",
        "    searcher_9 = textpage.search(\"termes d''indexation\", match_case=False, match_whole_word=True)\n",
        "    position_9 = searcher_9.get_next()\n",
        "    searcher_10 = textpage.search(\"termes-d''indexation\", match_case=False, match_whole_word=True)\n",
        "    position_10 = searcher_10.get_next()\n",
        "    searcher_11 = textpage.search(\"termes indexation\", match_case=False, match_whole_word=True)\n",
        "    position_11 = searcher_11.get_next()\n",
        "    searcher_12 = textpage.search(\"termes-indexation\", match_case=False, match_whole_word=True)\n",
        "    position_12 = searcher_12.get_next()\n",
        "    searcher_13 = textpage.search(\"motsclés\", match_case=False, match_whole_word=True)\n",
        "    position_13 = searcher_13.get_next()\n",
        "    searcher_14 = textpage.search(\"motscles\", match_case=False, match_whole_word=True)\n",
        "    position_14 = searcher_14.get_next()\n",
        "\n",
        "    if position_1:\n",
        "        position = position_1\n",
        "    elif position_2:\n",
        "        position = position_2\n",
        "    elif position_3:\n",
        "        position = position_3\n",
        "    elif position_4:\n",
        "        position = position_4\n",
        "    elif position_5:\n",
        "        position = position_5\n",
        "    elif position_6:\n",
        "        position = position_6\n",
        "    elif position_7:\n",
        "        position = position_7\n",
        "    elif position_8:\n",
        "        position = position_8\n",
        "    elif position_9:\n",
        "        position = position_9\n",
        "    elif position_10:\n",
        "        position = position_10\n",
        "    elif position_11:\n",
        "        position = position_11\n",
        "    elif position_12:\n",
        "        position = position_12\n",
        "    elif position_13:\n",
        "        position = position_13\n",
        "    elif position_14:\n",
        "        position = position_14\n",
        "    \n",
        "    if position:\n",
        "        return textpage.get_text_bounded(left=0, right=width, top=position[0][3])\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def abstract_arabic(height, width, textpage):\n",
        "\n",
        "    position = ()\n",
        "    \n",
        "    searcher_1 = textpage.search(\"ملخص\", match_case=False, match_whole_word=True)\n",
        "    position_1 = searcher_1.get_next()\n",
        "    searcher_2 = textpage.search(\"الملخص\", match_case=False, match_whole_word=True)\n",
        "    position_2 = searcher_2.get_next()\n",
        "\n",
        "    if position_1:\n",
        "        position = position_1\n",
        "    elif position_2:\n",
        "        position = position_2\n",
        "    \n",
        "    if position:\n",
        "        return textpage.get_text_bounded(left=0, right=width, top=position[0][3])\n",
        "    else:\n",
        "        return ''\n",
        "    \n",
        "def keywords_arabic(height, width, textpage):\n",
        "\n",
        "    position = ()\n",
        "    \n",
        "    searcher_1 = textpage.search(\"الكلمات المفتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_1 = searcher_1.get_next()\n",
        "    searcher_2 = textpage.search(\"الكلمات-المفتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_2 = searcher_2.get_next()\n",
        "    searcher_3 = textpage.search(\"الكلمات الافتتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_3 = searcher_3.get_next()\n",
        "    searcher_4 = textpage.search(\"الكلمات-الافتتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_4 = searcher_4.get_next()\n",
        "    searcher_5 = textpage.search(\"الكلمات المفتاح\", match_case=False, match_whole_word=True)\n",
        "    position_5 = searcher_5.get_next()\n",
        "    searcher_6 = textpage.search(\"الكلمات-المفتاح\", match_case=False, match_whole_word=True)\n",
        "    position_6 = searcher_6.get_next()\n",
        "    searcher_7 = textpage.search(\"كلمات مفتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_7 = searcher_7.get_next()\n",
        "    searcher_8 = textpage.search(\"كلمات-مفتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_8 = searcher_8.get_next()\n",
        "    searcher_9 = textpage.search(\"كلمات افتتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_9 = searcher_9.get_next()\n",
        "    searcher_10 = textpage.search(\"كلمات-افتتاحية\", match_case=False, match_whole_word=True)\n",
        "    position_10 = searcher_10.get_next()\n",
        "    searcher_11 = textpage.search(\"كلمات مفتاح\", match_case=False, match_whole_word=True)\n",
        "    position_11 = searcher_11.get_next()\n",
        "    searcher_12 = textpage.search(\"كلمات-مفتاح\", match_case=False, match_whole_word=True)\n",
        "    position_12 = searcher_12.get_next()\n",
        "\n",
        "    if position_1:\n",
        "        position = position_1\n",
        "    elif position_2:\n",
        "        position = position_2\n",
        "    elif position_3:\n",
        "        position = position_3\n",
        "    elif position_4:\n",
        "        position = position_4\n",
        "    elif position_5:\n",
        "        position = position_5\n",
        "    elif position_6:\n",
        "        position = position_6\n",
        "    elif position_7:\n",
        "        position = position_7\n",
        "    elif position_8:\n",
        "        position = position_8\n",
        "    elif position_9:\n",
        "        position = position_9\n",
        "    elif position_10:\n",
        "        position = position_10\n",
        "    elif position_11:\n",
        "        position = position_11\n",
        "    elif position_12:\n",
        "        position = position_12\n",
        "    \n",
        "    if position:\n",
        "        return textpage.get_text_bounded(left=0, right=width, top=position[0][3])\n",
        "    else:\n",
        "        return ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVSFgK_WZSkO"
      },
      "source": [
        "**Module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "bNRpIrA1AhMp"
      },
      "outputs": [],
      "source": [
        "def main_extract(path):\n",
        "\n",
        "    pdf = pdfium.PdfDocument(path) # open pdf\n",
        "\n",
        "    if len(pdf) <= 60: # limit to first and last 30 pages\n",
        "        n_pages = chain(range(len(pdf)))\n",
        "    else:\n",
        "        n_pages = chain(range(30), range(len(pdf)-30, len(pdf)))\n",
        "\n",
        "    en_a = ''\n",
        "    en_k = ''\n",
        "    fr_a = ''\n",
        "    fr_k = ''\n",
        "    ar_a = ''\n",
        "    ar_k = ''\n",
        "\n",
        "    regex = 'table de matières|table de matieres|table des matieres|table de matiere|table de matière|table des matières|sommaire|table of contents|table of content'\n",
        "    ar_regex = 'فهرس|الفهرس|جدول المحتويات|قائمة المحتويات|قائمة-المحتويات|جدول-المحتويات'\n",
        "    rf_regex = 'références|references|réferences|reférences'\n",
        "    ar_rf_regex = 'المراجع'\n",
        "\n",
        "\n",
        "    for i in n_pages:\n",
        "        page = pdf[i] \n",
        "        textpage = page.get_textpage() # get text\n",
        "        width, height = page.get_size()\n",
        "      \n",
        "   \n",
        "        text = textpage.get_text_range()\n",
        "        text = arabic_reshaper.reshape(text)\n",
        "        if re.search(regex, text, re.IGNORECASE) or re.search(ar_regex, text, re.IGNORECASE): # remove table of contents \n",
        "            pass\n",
        "        elif re.search(rf_regex, text, re.IGNORECASE) or re.search(ar_rf_regex, text, re.IGNORECASE): # stop at references \n",
        "            break\n",
        "\n",
        "        else:\n",
        "            if en_a == '': # extract abstract written in english\n",
        "                en_a = abstract_english(height, width, textpage)\n",
        "\n",
        "            if en_k == '': # extract keywords written in english\n",
        "                en_k = keywords_english(height, width, textpage)\n",
        "\n",
        "            if fr_a == '':\n",
        "                fr_a = abstract_french(height, width, textpage)\n",
        "\n",
        "            if fr_k == '':  # extract keywords written in french\n",
        "                fr_k = keywords_french(height, width, textpage)\n",
        "\n",
        "            if ar_a == '':  # extract abstract written in arabic\n",
        "                ar_a = abstract_arabic(height, width, textpage)\n",
        "            \n",
        "            if ar_k == '':\n",
        "                ar_k = keywords_arabic(height, width, textpage)\n",
        "\n",
        "            if en_a != '' and en_k != '' and fr_a != '' and fr_k != '' and ar_a != '' and ar_k != '':\n",
        "                break\n",
        "\n",
        "    # remove special characters\n",
        "    en_a = re.sub(\"[^a-zA-Zèéêùúîûôòóœàáâ!:;+=%$@,.?_(){}*'\\d\\s']\", '', en_a)\n",
        "    en_a = en_a.replace(en_k, '')\n",
        "    en_a = en_a.replace(fr_a, '')\n",
        "    en_a = en_a.replace(fr_k, '')\n",
        "    en_a = clean_data(en_a)\n",
        "    en_k = re.sub(\"[^a-zA-Zèéêùúîûôòóœàáâ!:;+=%$@,.?_(){}*'\\d\\s']\", '', en_k)\n",
        "    en_k = en_k.replace(en_a, '')\n",
        "    en_k = en_k.replace(fr_a, '')\n",
        "    en_k = en_k.replace(fr_k, '')\n",
        "    en_k = clean_data(en_k)\n",
        "    fr_a = re.sub(\"[^a-zA-Zèéêùúîûôòóœàáâ!:;+=%$@,.?_(){}*'\\d\\s']\", '', fr_a)\n",
        "    fr_a = fr_a.replace(en_k, '')\n",
        "    fr_a = fr_a.replace(en_a, '')\n",
        "    fr_a = fr_a.replace(fr_k, '')\n",
        "    fr_a = clean_data(fr_a)\n",
        "    fr_k = re.sub(\"[^a-zA-Zèéêùúîûôòóœàáâ!:;+=%$@,.?_(){}*'\\d\\s']\", '', fr_k)\n",
        "    fr_k = fr_k.replace(en_k, '')\n",
        "    fr_k = fr_k.replace(en_a, '')\n",
        "    fr_k = fr_k.replace(fr_a, '')\n",
        "    fr_k = clean_data(fr_k)\n",
        "    ar_a = ' '.join(tokenize(ar_a, conditions=is_arabicrange, morphs=strip_tashkeel))\n",
        "    ar_a = ar_a.replace(ar_k, '')\n",
        "    ar_a = clean_data(ar_a)\n",
        "    ar_a = arabic_reshaper.reshape(ar_a)\n",
        "    ar_k = ' '.join(tokenize(ar_k, conditions=is_arabicrange, morphs=strip_tashkeel))\n",
        "    ar_k = ar_k.replace(ar_a, '')\n",
        "    ar_k = clean_data(ar_k)\n",
        "    ar_k = arabic_reshaper.reshape(ar_k)\n",
        "\n",
        "    # remove introduction\n",
        "    regex = 'introduction|préface|preface|préambule|preambule'\n",
        "    ar_regex = 'مدخل|تمهيد|مقدمة'\n",
        "    mtch = re.search(regex, en_a, re.IGNORECASE)\n",
        "    if mtch:\n",
        "        pos = mtch.start()\n",
        "        en_a = en_a[0: pos]\n",
        "    mtch = re.search(regex, en_k, re.IGNORECASE)\n",
        "    if mtch:\n",
        "        pos = mtch.start()\n",
        "        en_k = en_k[0: pos]\n",
        "    mtch = re.search(regex, fr_a, re.IGNORECASE)\n",
        "    if mtch:\n",
        "        pos = mtch.start()\n",
        "        fr_a = fr_a[0: pos]\n",
        "    mtch = re.search(regex, fr_k, re.IGNORECASE)\n",
        "    if mtch:\n",
        "        pos = mtch.start()\n",
        "        fr_k = fr_k[0: pos]\n",
        "    mtch = re.search(ar_regex, ar_a, re.IGNORECASE)\n",
        "    if mtch:\n",
        "        pos = mtch.start()\n",
        "        ar_a = ar_a[0: pos]\n",
        "    mtch = re.search(ar_regex, ar_k, re.IGNORECASE)\n",
        "    if mtch:\n",
        "        pos = mtch.start()\n",
        "        ar_k = ar_k[0: pos]\n",
        "    \n",
        "    # remove noise\n",
        "    if len(en_a) <= 300 : en_a = ''\n",
        "    if len(fr_a) <= 300 : fr_a = ''\n",
        "    if len(ar_a) <= 300 : ar_a = ''\n",
        "    if len(en_k) >= 200 : en_k = ''\n",
        "    if len(fr_k) >= 200 : fr_k = ''\n",
        "    if len(ar_k) >= 200 : ar_k = ''\n",
        "\n",
        "    return [en_a, en_k, fr_a, fr_k, ar_a, ar_k]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
