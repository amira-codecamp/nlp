{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0G50qd8WCUfG"
      },
      "source": [
        "**Required**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s97kaUIiCYSH"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import pandas\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize\n",
        "!pip install arabic-reshaper\n",
        "!pip install PyArabic\n",
        "import arabic_reshaper\n",
        "from pyarabic.araby import strip_tatweel, strip_tashkeel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nxJf2kmEH8nP"
      },
      "outputs": [],
      "source": [
        "# Clean input text\n",
        "def clean(text):\n",
        "\n",
        "    # remove stop-words\n",
        "    stopwords = set(nltk.corpus.stopwords.words('english')) | set(nltk.corpus.stopwords.words('french')) | set(nltk.corpus.stopwords.words('arabic'))\n",
        "    text = ' '.join([word for word in word_tokenize(text) if word.lower() not in stopwords])\n",
        "\n",
        "    # remove prepostitions\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    tags = ['NN','NNP','NNS','NNPS','JJ','JJR','JJS','RB','RBR','RBS','VB','VBD','VBG','VBN','VBP','VBZ','FW','CD']\n",
        "    text = ' '.join([t[0] for t in tagged if t[1] in tags])\n",
        "\n",
        "    # reshape arabic\n",
        "    text = arabic_reshaper.reshape(text) \n",
        "        \n",
        "    # remove diactrics\n",
        "    text = strip_tatweel(text)\n",
        "    text = strip_tashkeel(text)\n",
        "\n",
        "    #\n",
        "    text = text.replace('\\n', ' ')\n",
        "\n",
        "    return text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "********"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vBiDhLz5Aksa"
      },
      "outputs": [],
      "source": [
        "# Classify text using neural network\n",
        "def classify(path, text):\n",
        "    \n",
        "    text = clean(text)\n",
        "    model = joblib.load(path) # load \n",
        "    categ = model.predict([text])[0] # predict \n",
        "\n",
        "    return categ"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
